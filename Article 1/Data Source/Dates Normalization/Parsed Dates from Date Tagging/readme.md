# Date Extraction Pipeline

**Author:** Samuel Jiang  
**Last Updated:** November 2025  

---

## Overview

This repository contains the **date extraction pipeline** for multilingual Wikipedia-derived text datasets.  
It processes the outputs of **date-tagging system**, which adds `<date>` tags around temporal expressions, and extracts the actual **numerical year values** (e.g., 1854, 400 BC, 2012) into clean CSV files.

---

## Data Source

The input data:
Each folder contains one or more `.csv` files generated by the **date tagging** step.  
Every file has at least two columns we will use in the step:

| Column | Description |
|:-------|:-------------|
| `filename` | The language of the file |
| `date_tagged` | The text with inline `<date>` tags around detected temporal phrases |

---

## What the Script Does

The main script, `extract_years_pipeline.py`, takes these tagged CSVs as input and produces simplified CSVs that record all parsed year values for each file.

**In one sentence:**  
> The code reads every tagged file, extracts numeric years from `<date>` tags, filters noise, and outputs one summary CSV per dataset.

**Key operations include:**
- Detects and parses `<date> ... </date>` tags.
- Recognizes **BC/BCE**, **AD/CE**, **ISO dates**, and **month-day-year** patterns.
- Ignores **centuries**, **decades**, **dynasty names**, and ambiguous **year ranges** (e.g., 1200–1300).
- Handles malformed inputs (e.g., “4000,000” or multi-thousand numbers).
- Outputs one CSV per subfolder to the user’s **Desktop**:
  ```
  parsed_years_historical_objects_tagged.csv
  parsed_years_history_of_ideologies_tagged.csv
  parsed_years_history_of_sports_tagged.csv
  ```

Each output CSV contains:

| Column | Description |
|:--------|:-------------|
| `filename` | Original text filename |
| `parsed_years` | Comma-separated list of extracted year values |

---

## Output Example

```
filename,parsed_years
ancient_art.txt,-500
modern_society.txt,1968,1990,2001
sports_in_rome.txt,-300,64
```

---

## Code Structure

```
extract_years_pipeline.py
├── extract_years()       → parses a single <date> tag
├── extract_dates()       → extracts all <date> tags in a cell
├── process_subfolder()   → processes all CSVs in a given dataset folder
├── main()                → iterates through all subfolders
└── _test_extract()       → unit test for sample inputs
```

Each function contributes to a modular, transparent, and easily testable workflow.

---

## Quick Test

To verify functionality, the script includes a self-test:

```bash
python3 extract_years_pipeline.py
```

You’ll see example inputs and parsed outputs, e.g.:

```
Input: 2012-02-29 → Parsed: [2012]
Input: 4000-2000 BCE → Parsed: []
Input: 4,000 BC → Parsed: [-4000]
```

## Summary

- **Input:** Rosie’s date-tagged CSVs (`*_tagged.csv`)  
- **Output:** Clean year lists (`parsed_years_*.csv`)  
- **Goal:** Prepare structured year data for temporal visualization and statistical modeling  
